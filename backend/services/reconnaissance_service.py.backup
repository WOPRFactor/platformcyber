"""
Reconnaissance Service
======================

Servicio completo para reconocimiento y OSINT.

Herramientas integradas:
- Subdomain Enumeration: Subfinder, Amass, Assetfinder, Sublist3r
- DNS: DNSRecon, fierce, dig
- Web Crawling: Katana, GoSpider, Hakrawler
- OSINT: theHarvester, Shodan, Censys
- Historical: Wayback Machine (waybackurls)
- Secrets: GitLeaks, TruffleHog
"""

import subprocess
import logging
import json
import threading
from typing import Dict, Any, List, Optional
from pathlib import Path
from datetime import datetime

from utils.validators import CommandSanitizer, DomainValidator, IPValidator
from utils.parsers.recon_parser import ReconParser
from utils.workspace_logger import log_to_workspace
from repositories import ScanRepository
from models import db

logger = logging.getLogger(__name__)


class ReconnaissanceService:
    """Servicio completo de reconnaissance y OSINT."""
    
    def __init__(self, scan_repository: ScanRepository = None):
        """Inicializa el servicio."""
        self.scan_repo = scan_repository or ScanRepository()
        self.output_dir = Path('/tmp/recon')
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.parser = ReconParser()
    
    # ============================================
    # SUBDOMAIN ENUMERATION
    # ============================================
    
    def start_subdomain_enum(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        tool: str = 'subfinder',
        passive_only: bool = True
    ) -> Dict[str, Any]:
        """
        Inicia enumeración de subdominios.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            tool: Herramienta (subfinder, amass, assetfinder, sublist3r)
            passive_only: Solo técnicas pasivas
        
        Returns:
            Dict con información del escaneo
        """
        # Validar dominio
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        # Crear scan
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': tool,
                'recon_type': 'subdomain_enum',
                'passive_only': passive_only
            }
        )
        
        try:
            output_file = str(self.output_dir / f'{tool}_{scan.id}.txt')
            
            # Construir comando según herramienta
            if tool == 'subfinder':
                command = [
                    'subfinder',
                    '-d', domain,
                    '-all',  # Todas las fuentes
                    '-recursive',  # Recursivo
                    '-o', output_file,
                    '-silent'
                ]
            
            elif tool == 'amass':
                mode = 'enum -passive' if passive_only else 'enum'
                command = [
                    'amass',
                    mode,
                    '-d', domain,
                    '-o', output_file
                ]
                if not passive_only:
                    command.extend(['-brute', '-w', '/usr/share/wordlists/amass/subdomains.txt'])
            
            elif tool == 'assetfinder':
                command = [
                    'assetfinder',
                    '--subs-only',
                    domain
                ]
            
            elif tool == 'sublist3r':
                command = [
                    'sublist3r',
                    '-d', domain,
                    '-o', output_file
                ]
                if not passive_only:
                    command.append('-b')  # Brute force
            
            else:
                raise ValueError(f'Unsupported tool: {tool}')
            
            # Sanitizar
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting subdomain enum {scan.id} with {tool}")
            
            # Ejecutar en thread separado
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'subdomain')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'target': domain,
                'passive_only': passive_only
            }
            
        except Exception as e:
            logger.error(f"Error starting subdomain enum: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # WHOIS LOOKUP
    # ============================================
    
    def start_whois_lookup(
        self,
        target: str,
        workspace_id: int,
        user_id: int
    ) -> Dict[str, Any]:
        """
        Inicia consulta WHOIS.
        
        Args:
            target: Dominio o IP objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
        
        Returns:
            Dict con información del escaneo
        """
        # Validar target (puede ser dominio o IP)
        if not DomainValidator.is_valid_domain(target) and not IPValidator.is_valid_ip(target):
            raise ValueError(f'Invalid target: {target}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=target,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'whois',
                'recon_type': 'whois'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'whois_{scan.id}.txt')
            
            command = ['whois', target]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting WHOIS lookup {scan.id} for {target}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'whois')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'whois',
                'target': target
            }
            
        except Exception as e:
            logger.error(f"Error starting WHOIS lookup: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # DNS ENUMERATION
    # ============================================
    
    def start_dns_recon(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        record_types: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """
        Inicia reconocimiento DNS.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            record_types: Tipos de registros (A, AAAA, MX, NS, TXT, SOA)
        
        Returns:
            Dict con información del escaneo
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        if not record_types:
            record_types = ['A', 'AAAA', 'MX', 'NS', 'TXT', 'SOA', 'CNAME']
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'dnsrecon',
                'recon_type': 'dns',
                'record_types': record_types
            }
        )
        
        try:
            output_file = str(self.output_dir / f'dnsrecon_{scan.id}.json')
            
            command = [
                'dnsrecon',
                '-d', domain,
                '-t', 'std',  # Standard enumeration
                '-j', output_file  # JSON output
            ]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting DNS recon {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'dns')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'dnsrecon',
                'target': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting DNS recon: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # EMAIL HARVESTING
    # ============================================
    
    def start_email_harvest(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        sources: str = 'google,bing,linkedin,twitter',
        limit: int = 500
    ) -> Dict[str, Any]:
        """
        Busca emails con theHarvester.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            sources: Fuentes separadas por coma
            limit: Límite de resultados
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'theHarvester',
                'recon_type': 'email_harvest',
                'sources': sources,
                'limit': limit
            }
        )
        
        try:
            output_file = str(self.output_dir / f'harvester_{scan.id}')
            
            command = [
                'theHarvester',
                '-d', domain,
                '-b', sources,
                '-l', str(limit),
                '-f', output_file
            ]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting email harvest {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file + '.json', 'email')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'theHarvester',
                'target': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting email harvest: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # WEB CRAWLING
    # ============================================
    
    def start_web_crawl(
        self,
        url: str,
        workspace_id: int,
        user_id: int,
        tool: str = 'katana',
        depth: int = 3,
        scope: str = 'same-domain'
    ) -> Dict[str, Any]:
        """
        Inicia crawling web.
        
        Args:
            url: URL objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            tool: Herramienta (katana, gospider, hakrawler)
            depth: Profundidad del crawl
            scope: Alcance (same-domain, subdomain, all)
        """
        if not DomainValidator.validate_url(url):
            raise ValueError(f'Invalid URL: {url}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=url,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': tool,
                'recon_type': 'web_crawl',
                'depth': depth,
                'scope': scope
            }
        )
        
        try:
            output_file = str(self.output_dir / f'{tool}_{scan.id}.txt')
            
            if tool == 'katana':
                command = [
                    'katana',
                    '-u', url,
                    '-d', str(depth),
                    '-jc',  # JavaScript crawling
                    '-kf', 'all',  # Known files
                    '-o', output_file
                ]
                
                if scope == 'same-domain':
                    command.append('-s')  # Same domain only
            
            elif tool == 'gospider':
                command = [
                    'gospider',
                    '-s', url,
                    '-d', str(depth),
                    '-c', '10',  # Concurrent requests
                    '-o', str(self.output_dir)
                ]
            
            elif tool == 'hakrawler':
                command = [
                    'echo', url,
                    '|',
                    'hakrawler',
                    '-d', str(depth),
                    '-u'  # Unique URLs only
                ]
            
            else:
                raise ValueError(f'Unsupported tool: {tool}')
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting web crawl {scan.id} with {tool}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'crawl')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'target': url,
                'depth': depth
            }
            
        except Exception as e:
            logger.error(f"Error starting web crawl: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # WAYBACK MACHINE (Historical URLs)
    # ============================================
    
    def start_wayback_urls(
        self,
        domain: str,
        workspace_id: int,
        user_id: int
    ) -> Dict[str, Any]:
        """
        Obtiene URLs históricas de Wayback Machine.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'waybackurls',
                'recon_type': 'historical'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'wayback_{scan.id}.txt')
            
            command = [
                'waybackurls',
                domain
            ]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting Wayback URLs {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'wayback')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'waybackurls',
                'target': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting Wayback URLs: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # SECRETS DETECTION
    # ============================================
    
    def start_secrets_scan(
        self,
        repo_url: str,
        workspace_id: int,
        user_id: int,
        tool: str = 'gitleaks'
    ) -> Dict[str, Any]:
        """
        Busca secrets/credentials en repositorios.
        
        Args:
            repo_url: URL del repositorio
            workspace_id: ID del workspace
            user_id: ID del usuario
            tool: Herramienta (gitleaks, trufflehog)
        """
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=repo_url,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': tool,
                'recon_type': 'secrets'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'{tool}_{scan.id}.json')
            
            if tool == 'gitleaks':
                command = [
                    'gitleaks',
                    'detect',
                    '--repo-url', repo_url,
                    '--report-format', 'json',
                    '--report-path', output_file,
                    '--no-git'
                ]
            
            elif tool == 'trufflehog':
                command = [
                    'trufflehog',
                    'git',
                    repo_url,
                    '--json',
                    '--only-verified'
                ]
            
            else:
                raise ValueError(f'Unsupported tool: {tool}')
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting secrets scan {scan.id} with {tool}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'secrets')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'target': repo_url
            }
            
        except Exception as e:
            logger.error(f"Error starting secrets scan: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # SHODAN INTEGRATION
    # ============================================
    
    def start_shodan_search(
        self,
        query: str,
        workspace_id: int,
        user_id: int,
        api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Busca información en Shodan.
        
        Args:
            query: Query de búsqueda (IP, domain, org)
            workspace_id: ID del workspace
            user_id: ID del usuario
            api_key: API key de Shodan
        
        Note:
            Requiere shodan CLI instalado y configurado
        """
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=query,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'shodan',
                'recon_type': 'osint'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'shodan_{scan.id}.json')
            
            command = [
                'shodan',
                'search',
                '--fields', 'ip_str,port,org,data,vulns',
                query
            ]
            
            if api_key:
                command.extend(['--api-key', api_key])
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            logger.info(f"Starting Shodan search {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'shodan')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'shodan',
                'query': query
            }
            
        except Exception as e:
            logger.error(f"Error starting Shodan search: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # CERTIFICATE TRANSPARENCY (crt.sh)
    # ============================================
    
    def start_crtsh_lookup(
        self,
        domain: str,
        workspace_id: int,
        user_id: int
    ) -> Dict[str, Any]:
        """
        Busca subdominios usando Certificate Transparency (crt.sh).
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
        
        Returns:
            Dict con información del escaneo
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'crtsh',
                'recon_type': 'subdomain_enum'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'crtsh_{scan.id}.txt')
            
            # Usar curl para consultar crt.sh API
            import urllib.parse
            encoded_domain = urllib.parse.quote(f'%.{domain}')
            url = f'https://crt.sh/?q={encoded_domain}&output=json'
            
            command = [
                'curl',
                '-s',
                url
            ]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source='CRTSH',
                level='INFO',
                message=f"Iniciando búsqueda Certificate Transparency para {domain}",
                metadata={'scan_id': scan.id, 'domain': domain}
            )
            
            logger.info(f"Starting crt.sh lookup {scan.id}")
            
            # Ejecutar en thread
            thread = threading.Thread(
                target=self._execute_crtsh_scan,
                args=(scan.id, sanitized_cmd, output_file, domain, workspace_id)
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'crtsh',
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting crt.sh lookup: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    def _execute_crtsh_scan(
        self,
        scan_id: int,
        command: list,
        output_file: str,
        domain: str,
        workspace_id: int
    ) -> None:
        """Ejecuta scan de crt.sh y parsea JSON."""
        try:
            import json
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                timeout=300,
                env=CommandSanitizer.get_safe_env()
            )
            
            if result.returncode == 0:
                # Parsear JSON y extraer subdominios
                try:
                    data = json.loads(result.stdout)
                    subdomains = set()
                    for entry in data:
                        if 'name_value' in entry:
                            names = entry['name_value'].split('\n')
                            for name in names:
                                name = name.strip()
                                if name and domain in name:
                                    subdomains.add(name)
                    
                    # Guardar subdominios
                    with open(output_file, 'w') as f:
                        for subdomain in sorted(subdomains):
                            f.write(f"{subdomain}\n")
                    
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='CRTSH',
                        level='INFO',
                        message=f"crt.sh completado: {len(subdomains)} subdominios encontrados",
                        metadata={'scan_id': scan_id, 'subdomains_count': len(subdomains)}
                    )
                    
                except json.JSONDecodeError:
                    # Si no es JSON válido, guardar raw output
                    with open(output_file, 'w') as f:
                        f.write(result.stdout)
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='CRTSH',
                        level='WARNING',
                        message="crt.sh: respuesta no es JSON válido, guardando raw output",
                        metadata={'scan_id': scan_id}
                    )
                
                scan = self.scan_repo.find_by_id(scan_id)
                self.scan_repo.update_status(scan, 'completed')
                logger.info(f"crt.sh scan {scan_id} completed")
            else:
                error_msg = result.stderr or "Unknown error"
                scan = self.scan_repo.find_by_id(scan_id)
                self.scan_repo.update_status(scan, 'failed', error_msg)
                log_to_workspace(
                    workspace_id=workspace_id,
                    source='CRTSH',
                    level='ERROR',
                    message=f"crt.sh falló: {error_msg}",
                    metadata={'scan_id': scan_id, 'error': error_msg}
                )
                logger.error(f"crt.sh scan {scan_id} failed: {error_msg}")
                
        except Exception as e:
            scan = self.scan_repo.find_by_id(scan_id)
            self.scan_repo.update_status(scan, 'failed', str(e))
            log_to_workspace(
                workspace_id=workspace_id,
                source='CRTSH',
                level='ERROR',
                message=f"Error en crt.sh: {str(e)}",
                metadata={'scan_id': scan_id, 'error': str(e)}
            )
            logger.error(f"crt.sh scan {scan_id} error: {e}", exc_info=True)
    
    # ============================================
    # FINDOMAIN
    # ============================================
    
    def start_findomain_enum(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        resolvers_file: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Enumeración de subdominios con Findomain.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            resolvers_file: Archivo de resolvers DNS (opcional)
        
        Returns:
            Dict con información del escaneo
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'findomain',
                'recon_type': 'subdomain_enum'
            }
        )
        
        try:
            output_file = str(self.output_dir / f'findomain_{scan.id}.txt')
            
            command = [
                'findomain',
                '-t', domain,
                '-o'
            ]
            
            if resolvers_file:
                command.extend(['--resolvers', resolvers_file])
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source='FINDOMAIN',
                level='INFO',
                message=f"Iniciando Findomain para {domain}",
                metadata={'scan_id': scan.id, 'domain': domain}
            )
            
            logger.info(f"Starting Findomain enum {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'findomain')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'findomain',
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting Findomain enum: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # CENSYS
    # ============================================
    
    def start_censys_search(
        self,
        query: str,
        workspace_id: int,
        user_id: int,
        index_type: str = 'hosts',
        api_id: Optional[str] = None,
        api_secret: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Busca información en Censys.
        
        Args:
            query: Query de búsqueda
            workspace_id: ID del workspace
            user_id: ID del usuario
            index_type: Tipo de índice ('hosts' o 'certificates')
            api_id: API ID de Censys (opcional, puede estar en env)
            api_secret: API Secret de Censys (opcional, puede estar en env)
        
        Returns:
            Dict con información del escaneo
        """
        import os
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=query,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'censys',
                'recon_type': 'osint',
                'index_type': index_type
            }
        )
        
        try:
            output_file = str(self.output_dir / f'censys_{scan.id}.json')
            
            # Obtener credenciales de env si no se proporcionan
            api_id = api_id or os.getenv('CENSYS_API_ID')
            api_secret = api_secret or os.getenv('CENSYS_API_SECRET')
            
            if not api_id or not api_secret:
                raise ValueError('Censys API credentials required (CENSYS_API_ID and CENSYS_API_SECRET)')
            
            command = [
                'censys',
                'search',
                query,
                '--index-type', index_type,
                '--api-id', api_id,
                '--api-secret', api_secret
            ]
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source='CENSYS',
                level='INFO',
                message=f"Iniciando búsqueda Censys ({index_type}) para: {query}",
                metadata={'scan_id': scan.id, 'query': query, 'index_type': index_type}
            )
            
            logger.info(f"Starting Censys search {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'censys')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'censys',
                'query': query,
                'index_type': index_type
            }
            
        except Exception as e:
            logger.error(f"Error starting Censys search: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # DNS LOOKUP (host/nslookup)
    # ============================================
    
    def start_dns_lookup(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        tool: str = 'host',
        record_type: Optional[str] = None,
        dns_server: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Consultas DNS simples con host o nslookup.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            tool: Herramienta ('host' o 'nslookup')
            record_type: Tipo de registro (A, MX, NS, TXT, SOA, etc.)
            dns_server: Servidor DNS específico (opcional)
        
        Returns:
            Dict con información del escaneo
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        if tool not in ['host', 'nslookup']:
            raise ValueError(f'Invalid tool: {tool}. Must be "host" or "nslookup"')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': tool,
                'recon_type': 'dns_lookup',
                'record_type': record_type
            }
        )
        
        try:
            output_file = str(self.output_dir / f'{tool}_{scan.id}.txt')
            
            if tool == 'host':
                command = ['host', domain]
                if record_type:
                    command.extend(['-t', record_type])
                if dns_server:
                    command.extend([dns_server])
            else:  # nslookup
                command = ['nslookup', domain]
                if record_type:
                    command.extend(['-type', record_type])
                if dns_server:
                    command.append(dns_server)
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source=tool.upper(),
                level='INFO',
                message=f"Iniciando {tool} lookup para {domain}",
                metadata={'scan_id': scan.id, 'domain': domain, 'record_type': record_type}
            )
            
            logger.info(f"Starting {tool} lookup {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, tool)
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting {tool} lookup: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # TRACEROUTE
    # ============================================
    
    def start_traceroute(
        self,
        target: str,
        workspace_id: int,
        user_id: int,
        protocol: str = 'icmp',
        max_hops: int = 30
    ) -> Dict[str, Any]:
        """
        Mapeo de ruta de red con traceroute.
        
        Args:
            target: IP o dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            protocol: Protocolo ('icmp', 'tcp', 'udp')
            max_hops: Número máximo de saltos
        
        Returns:
            Dict con información del escaneo
        """
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=target,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': 'traceroute',
                'recon_type': 'network_mapping',
                'protocol': protocol
            }
        )
        
        try:
            output_file = str(self.output_dir / f'traceroute_{scan.id}.txt')
            
            command = ['traceroute', '-m', str(max_hops), target]
            
            if protocol == 'tcp':
                command.append('-T')
            elif protocol == 'udp':
                command.append('-U')
            # ICMP es el default
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source='TRACEROUTE',
                level='INFO',
                message=f"Iniciando traceroute ({protocol}) para {target}",
                metadata={'scan_id': scan.id, 'target': target, 'protocol': protocol}
            )
            
            logger.info(f"Starting traceroute {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, 'traceroute')
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'traceroute',
                'target': target
            }
            
        except Exception as e:
            logger.error(f"Error starting traceroute: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # DNS ENUMERATION ALTERNATIVAS (dnsenum/fierce)
    # ============================================
    
    def start_dns_enum_alt(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        tool: str = 'dnsenum',
        wordlist: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Enumeración DNS con dnsenum o fierce.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            tool: Herramienta ('dnsenum' o 'fierce')
            wordlist: Archivo wordlist para bruteforce (opcional)
        
        Returns:
            Dict con información del escaneo
        """
        if not DomainValidator.is_valid_domain(domain):
            raise ValueError(f'Invalid domain: {domain}')
        
        if tool not in ['dnsenum', 'fierce']:
            raise ValueError(f'Invalid tool: {tool}. Must be "dnsenum" or "fierce"')
        
        scan = self.scan_repo.create(
            scan_type='reconnaissance',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            options={
                'tool': tool,
                'recon_type': 'dns_enum',
                'wordlist': wordlist
            }
        )
        
        try:
            output_file = str(self.output_dir / f'{tool}_{scan.id}.txt')
            
            if tool == 'dnsenum':
                command = ['dnsenum', domain]
                if wordlist:
                    command.extend(['--enum', domain, '-f', wordlist])
            else:  # fierce
                command = ['fierce', '--domain', domain]
                if wordlist:
                    command.extend(['-w', wordlist])
            
            sanitized_cmd = CommandSanitizer.sanitize_command(command[0], command[1:])
            
            log_to_workspace(
                workspace_id=workspace_id,
                source=tool.upper(),
                level='INFO',
                message=f"Iniciando {tool} para {domain}",
                metadata={'scan_id': scan.id, 'domain': domain}
            )
            
            logger.info(f"Starting {tool} {scan.id}")
            
            thread = threading.Thread(
                target=self._execute_scan,
                args=(scan.id, sanitized_cmd, output_file, tool)
            )
            thread.daemon = True
            thread.start()
            
            self.scan_repo.update_status(scan, 'running')
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting {tool}: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # GOOGLE DORKS
    # ============================================
    
    def start_google_dorks(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        dork_query: Optional[str] = None,
        tool: str = 'manual'
    ) -> Dict[str, Any]:
        """
        Ejecuta Google Dorks manuales o automatizados.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            dork_query: Query de dork personalizado (para modo manual)
            tool: 'manual' | 'goofuzz' | 'pagodo' | 'dorkscanner'
        
        Returns:
            Dict con información del escaneo iniciado
        """
        DomainValidator.validate(domain)
        CommandSanitizer.validate_target(domain)
        
        scan = self.scan_repo.create_scan(
            scan_type='google_dorks',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            status='running'
        )
        
        output_file = self.output_dir / f"google_dorks_{scan.id}.txt"
        
        try:
            def execute_scan():
                try:
                    if tool == 'manual':
                        # Google Dork manual - construir query
                        if dork_query:
                            query = dork_query
                        else:
                            # Query por defecto
                            query = f"site:{domain}"
                        
                        # Guardar query en archivo (para referencia)
                        with open(output_file, 'w') as f:
                            f.write(f"Google Dork Query: {query}\n")
                            f.write(f"Domain: {domain}\n")
                            f.write(f"Tool: {tool}\n\n")
                            f.write("NOTA: Este es un dork manual. Ejecuta la búsqueda en Google:\n")
                            f.write(f"https://www.google.com/search?q={query.replace(' ', '+')}\n")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"Google Dork manual generado: {query}",
                            task_id=None
                        )
                        
                    elif tool == 'goofuzz':
                        # GooFuzz - búsqueda automatizada
                        extensions = ['pdf', 'doc', 'xls', 'sql', 'log', 'env']
                        cmd = ['goofuzz', '-t', domain, '-e', ','.join(extensions)]
                        
                        with open(output_file, 'w') as f:
                            result = subprocess.run(
                                cmd,
                                capture_output=True,
                                text=True,
                                timeout=300
                            )
                            f.write(result.stdout)
                            if result.stderr:
                                f.write(f"\n\nSTDERR:\n{result.stderr}")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"GooFuzz completado para {domain}",
                            task_id=None
                        )
                        
                    elif tool == 'pagodo':
                        # Pagodo - búsqueda con lista de dorks
                        dorks_file = Path('/tmp/pagodo_dorks.txt')
                        if not dorks_file.exists():
                            # Crear archivo de dorks por defecto
                            default_dorks = [
                                f"site:{domain} filetype:pdf",
                                f"site:{domain} filetype:doc",
                                f"site:{domain} filetype:xls",
                                f"site:{domain} inurl:admin",
                                f"site:{domain} inurl:login",
                                f"site:{domain} 'password'"
                            ]
                            with open(dorks_file, 'w') as f:
                                f.write('\n'.join(default_dorks))
                        
                        cmd = ['pagodo', '-d', domain, '-g', str(dorks_file)]
                        
                        with open(output_file, 'w') as f:
                            result = subprocess.run(
                                cmd,
                                capture_output=True,
                                text=True,
                                timeout=600
                            )
                            f.write(result.stdout)
                            if result.stderr:
                                f.write(f"\n\nSTDERR:\n{result.stderr}")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"Pagodo completado para {domain}",
                            task_id=None
                        )
                        
                    elif tool == 'dorkscanner':
                        # dorkScanner - scanner Python
                        cmd = ['python3', 'dorkScanner.py', '-d', domain]
                        
                        with open(output_file, 'w') as f:
                            result = subprocess.run(
                                cmd,
                                capture_output=True,
                                text=True,
                                timeout=600,
                                cwd='/tmp'
                            )
                            f.write(result.stdout)
                            if result.stderr:
                                f.write(f"\n\nSTDERR:\n{result.stderr}")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"dorkScanner completado para {domain}",
                            task_id=None
                        )
                    
                    self.scan_repo.update_status(scan, 'completed')
                    
                except subprocess.TimeoutExpired:
                    logger.error(f"Google Dorks timeout for {domain}")
                    self.scan_repo.update_status(scan, 'failed', 'Timeout')
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"Google Dorks timeout para {domain}",
                        task_id=None
                    )
                except Exception as e:
                    logger.error(f"Error in Google Dorks scan: {e}")
                    self.scan_repo.update_status(scan, 'failed', str(e))
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"Error en Google Dorks: {str(e)}",
                        task_id=None
                    )
            
            thread = threading.Thread(target=execute_scan)
            thread.daemon = True
            thread.start()
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting Google Dorks: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # HUNTER.IO
    # ============================================
    
    def start_hunter_io_search(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        api_key: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        Busca emails corporativos usando Hunter.io API.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            api_key: API key de Hunter.io (opcional, puede estar en env)
        
        Returns:
            Dict con información del escaneo iniciado
        """
        DomainValidator.validate(domain)
        CommandSanitizer.validate_target(domain)
        
        scan = self.scan_repo.create_scan(
            scan_type='hunter_io',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            status='running'
        )
        
        output_file = self.output_dir / f"hunter_io_{scan.id}.json"
        
        try:
            def execute_scan():
                try:
                    import requests
                    import os
                    
                    # Obtener API key de parámetro o variable de entorno
                    api_key_final = api_key or os.getenv('HUNTER_IO_API_KEY')
                    
                    if not api_key_final:
                        raise ValueError("Hunter.io API key no proporcionada. Configura HUNTER_IO_API_KEY en variables de entorno o pásala como parámetro.")
                    
                    # Llamar a la API de Hunter.io
                    url = f"https://api.hunter.io/v2/domain-search"
                    params = {
                        'domain': domain,
                        'api_key': api_key_final
                    }
                    
                    response = requests.get(url, params=params, timeout=30)
                    response.raise_for_status()
                    
                    data = response.json()
                    
                    # Guardar resultados
                    with open(output_file, 'w') as f:
                        json.dump(data, f, indent=2)
                    
                    # Log resultados
                    emails_found = data.get('data', {}).get('emails', [])
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='info',
                        message=f"Hunter.io: {len(emails_found)} emails encontrados para {domain}",
                        task_id=None
                    )
                    
                    self.scan_repo.update_status(scan, 'completed')
                    
                except requests.exceptions.RequestException as e:
                    logger.error(f"Hunter.io API error: {e}")
                    self.scan_repo.update_status(scan, 'failed', f"API Error: {str(e)}")
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"Error en Hunter.io API: {str(e)}",
                        task_id=None
                    )
                except Exception as e:
                    logger.error(f"Error in Hunter.io scan: {e}")
                    self.scan_repo.update_status(scan, 'failed', str(e))
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"Error en Hunter.io: {str(e)}",
                        task_id=None
                    )
            
            thread = threading.Thread(target=execute_scan)
            thread.daemon = True
            thread.start()
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': 'hunter_io',
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting Hunter.io: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # LINKEDIN ENUMERATION
    # ============================================
    
    def start_linkedin_enum(
        self,
        domain: str,
        workspace_id: int,
        user_id: int,
        company_name: Optional[str] = None,
        tool: str = 'crosslinked'
    ) -> Dict[str, Any]:
        """
        Enumera empleados usando LinkedIn.
        
        Args:
            domain: Dominio objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            company_name: Nombre de la compañía (opcional)
            tool: 'crosslinked' | 'linkedin2username'
        
        Returns:
            Dict con información del escaneo iniciado
        """
        DomainValidator.validate(domain)
        CommandSanitizer.validate_target(domain)
        
        scan = self.scan_repo.create_scan(
            scan_type='linkedin_enum',
            target=domain,
            workspace_id=workspace_id,
            user_id=user_id,
            status='running'
        )
        
        output_file = self.output_dir / f"linkedin_enum_{scan.id}.txt"
        
        try:
            def execute_scan():
                try:
                    if tool == 'crosslinked':
                        # CrossLinked - enumeración de usuarios
                        if not company_name:
                            company_name = domain.split('.')[0].title()
                        
                        # Patrón de email común
                        email_pattern = f"{{first}}.{{last}}@{domain}"
                        
                        cmd = ['crosslinked', '-f', email_pattern, company_name]
                        
                        with open(output_file, 'w') as f:
                            result = subprocess.run(
                                cmd,
                                capture_output=True,
                                text=True,
                                timeout=600
                            )
                            f.write(result.stdout)
                            if result.stderr:
                                f.write(f"\n\nSTDERR:\n{result.stderr}")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"CrossLinked completado para {domain}",
                            task_id=None
                        )
                        
                    elif tool == 'linkedin2username':
                        # linkedin2username - conversión de perfiles a usernames
                        if not company_name:
                            company_name = domain.split('.')[0].title()
                        
                        cmd = ['linkedin2username', '-u', f"user@{domain}", '-c', company_name]
                        
                        with open(output_file, 'w') as f:
                            result = subprocess.run(
                                cmd,
                                capture_output=True,
                                text=True,
                                timeout=600
                            )
                            f.write(result.stdout)
                            if result.stderr:
                                f.write(f"\n\nSTDERR:\n{result.stderr}")
                        
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source='reconnaissance',
                            level='info',
                            message=f"linkedin2username completado para {domain}",
                            task_id=None
                        )
                    
                    self.scan_repo.update_status(scan, 'completed')
                    
                except subprocess.TimeoutExpired:
                    logger.error(f"LinkedIn Enum timeout for {domain}")
                    self.scan_repo.update_status(scan, 'failed', 'Timeout')
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"LinkedIn Enum timeout para {domain}",
                        task_id=None
                    )
                except Exception as e:
                    logger.error(f"Error in LinkedIn Enum scan: {e}")
                    self.scan_repo.update_status(scan, 'failed', str(e))
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source='reconnaissance',
                        level='error',
                        message=f"Error en LinkedIn Enum: {str(e)}",
                        task_id=None
                    )
            
            thread = threading.Thread(target=execute_scan)
            thread.daemon = True
            thread.start()
            
            return {
                'scan_id': scan.id,
                'status': 'running',
                'tool': tool,
                'domain': domain
            }
            
        except Exception as e:
            logger.error(f"Error starting LinkedIn Enum: {e}")
            self.scan_repo.update_status(scan, 'failed', str(e))
            raise
    
    # ============================================
    # COMPLETE RECONNAISSANCE
    # ============================================
    
    def start_complete_recon(
        self,
        target: str,
        workspace_id: int,
        user_id: int,
        include_advanced: bool = False
    ) -> Dict[str, Any]:
        """
        Inicia reconocimiento completo (todas las fases básicas).
        
        Args:
            target: Dominio o IP objetivo
            workspace_id: ID del workspace
            user_id: ID del usuario
            include_advanced: Incluir herramientas avanzadas (secrets, shodan)
        
        Returns:
            Dict con información de todos los escaneos iniciados
        """
        results = {
            'target': target,
            'workspace_id': workspace_id,
            'phases': {},
            'scan_ids': []
        }
        
        # Fase 1: WHOIS
        try:
            whois_result = self.start_whois_lookup(target, workspace_id, user_id)
            results['phases']['whois'] = {
                'scan_id': whois_result['scan_id'],
                'status': 'running',
                'tool': 'whois'
            }
            results['scan_ids'].append(whois_result['scan_id'])
        except Exception as e:
            logger.error(f"Error starting WHOIS in complete recon: {e}")
            results['phases']['whois'] = {'status': 'failed', 'error': str(e)}
        
        # Fase 2: DNS (solo si es dominio)
        if DomainValidator.is_valid_domain(target):
            try:
                dns_result = self.start_dns_recon(target, workspace_id, user_id)
                results['phases']['dns'] = {
                    'scan_id': dns_result['scan_id'],
                    'status': 'running',
                    'tool': 'dnsrecon'
                }
                results['scan_ids'].append(dns_result['scan_id'])
            except Exception as e:
                logger.error(f"Error starting DNS in complete recon: {e}")
                results['phases']['dns'] = {'status': 'failed', 'error': str(e)}
        
        # Fase 3: Subdominios (solo si es dominio)
        if DomainValidator.is_valid_domain(target):
            try:
                subdomain_result = self.start_subdomain_enum(
                    domain=target,
                    workspace_id=workspace_id,
                    user_id=user_id,
                    tool='subfinder',
                    passive_only=True
                )
                results['phases']['subdomains'] = {
                    'scan_id': subdomain_result['scan_id'],
                    'status': 'running',
                    'tool': 'subfinder'
                }
                results['scan_ids'].append(subdomain_result['scan_id'])
            except Exception as e:
                logger.error(f"Error starting subdomain enum in complete recon: {e}")
                results['phases']['subdomains'] = {'status': 'failed', 'error': str(e)}
        
        # Fase 4: Emails (solo si es dominio)
        if DomainValidator.is_valid_domain(target):
            try:
                email_result = self.start_email_harvest(
                    domain=target,
                    workspace_id=workspace_id,
                    user_id=user_id
                )
                results['phases']['emails'] = {
                    'scan_id': email_result['scan_id'],
                    'status': 'running',
                    'tool': 'theHarvester'
                }
                results['scan_ids'].append(email_result['scan_id'])
            except Exception as e:
                logger.error(f"Error starting email harvest in complete recon: {e}")
                results['phases']['emails'] = {'status': 'failed', 'error': str(e)}
        
        # Fases avanzadas (opcional)
        if include_advanced and DomainValidator.is_valid_domain(target):
            # Wayback URLs
            try:
                wayback_result = self.start_wayback_urls(target, workspace_id, user_id)
                results['phases']['wayback'] = {
                    'scan_id': wayback_result['scan_id'],
                    'status': 'running',
                    'tool': 'waybackurls'
                }
                results['scan_ids'].append(wayback_result['scan_id'])
            except Exception as e:
                logger.error(f"Error starting wayback in complete recon: {e}")
                results['phases']['wayback'] = {'status': 'failed', 'error': str(e)}
        
        results['total_phases'] = len(results['phases'])
        results['status'] = 'running'
        
        return results
    
    # ============================================
    # PARSERS DE RESULTADOS
    # ============================================
    
    def get_scan_results(self, scan_id: int) -> Dict[str, Any]:
        """
        Obtiene y parsea resultados de un scan.
        
        Args:
            scan_id: ID del escaneo
        
        Returns:
            Dict con resultados parseados
        """
        scan = self.scan_repo.find_by_id(scan_id)
        
        if not scan:
            raise ValueError(f'Scan {scan_id} not found')
        
        if scan.status != 'completed':
            return {
                'scan_id': scan_id,
                'status': scan.status,
                'message': 'Scan not completed yet'
            }
        
        tool = scan.options.get('tool')
        recon_type = scan.options.get('recon_type')
        
        # Leer archivo de salida
        output_file = self._get_output_file(scan_id, tool)
        
        if not output_file.exists():
            return {
                'scan_id': scan_id,
                'error': 'Output file not found'
            }
        
        # Parsear según herramienta
        try:
            with open(output_file, 'r') as f:
                content = f.read()
            
            if tool == 'whois':
                # WHOIS output es texto plano, devolver directamente
                results = {
                    'tool': 'whois',
                    'output': content,
                    'lines': len(content.split('\n'))
                }
            elif tool == 'subfinder' or tool == 'assetfinder' or tool == 'sublist3r':
                results = self.parser.parse_subfinder(content)
            elif tool == 'amass':
                results = self.parser.parse_amass(content)
            elif tool == 'theHarvester':
                results = self.parser.parse_theharvester(str(output_file))
            elif tool == 'katana' or tool == 'gospider' or tool == 'hakrawler':
                results = self.parser.parse_katana(content)
            elif tool == 'dnsrecon':
                results = self.parser.parse_dnsrecon(content)
            elif tool == 'waybackurls':
                results = self.parser.parse_waybackurls(content)
            elif tool == 'shodan':
                results = self.parser.parse_shodan(content)
            elif tool == 'gitleaks' or tool == 'trufflehog':
                results = self.parser.parse_gitleaks(content)
            elif tool == 'crtsh':
                # crt.sh: subdominios por línea
                subdomains = [line.strip() for line in content.split('\n') if line.strip()]
                results = {
                    'subdomains': subdomains,
                    'total': len(subdomains)
                }
            elif tool == 'findomain':
                # Findomain: subdominios por línea
                subdomains = [line.strip() for line in content.split('\n') if line.strip()]
                results = {
                    'subdomains': subdomains,
                    'total': len(subdomains)
                }
            elif tool == 'censys':
                # Censys: JSON output
                try:
                    import json
                    results = json.loads(content)
                except json.JSONDecodeError:
                    results = {'raw_output': content}
            elif tool == 'host' or tool == 'nslookup':
                # DNS Lookup: texto plano
                results = {
                    'output': content,
                    'lines': len(content.split('\n'))
                }
            elif tool == 'traceroute':
                # Traceroute: texto plano
                results = {
                    'output': content,
                    'lines': len(content.split('\n'))
                }
            elif tool == 'dnsenum' or tool == 'fierce':
                # DNSenum/Fierce: parsear como DNSRecon
                results = self.parser.parse_dnsrecon(content)
            else:
                results = {'raw_output': content}
            
            return {
                'scan_id': scan_id,
                'status': 'completed',
                'tool': tool,
                'recon_type': recon_type,
                'results': results,
                'scan_info': {
                    'target': scan.target,
                    'started_at': scan.started_at.isoformat() if scan.started_at else None,
                    'completed_at': scan.completed_at.isoformat() if scan.completed_at else None
                }
            }
            
        except Exception as e:
            logger.error(f"Error parsing results for scan {scan_id}: {e}")
            return {
                'scan_id': scan_id,
                'error': f'Failed to parse results: {str(e)}'
            }
    
    # ============================================
    # HELPERS PRIVADOS
    # ============================================
    
    def _get_output_file(self, scan_id: int, tool: str) -> Path:
        """Obtiene path del archivo de salida."""
        extensions = {
            'theHarvester': '.json',
            'dnsrecon': '.json',
            'shodan': '.json',
            'gitleaks': '.json',
            'trufflehog': '.json'
        }
        ext = extensions.get(tool, '.txt')
        return self.output_dir / f'{tool}_{scan_id}{ext}'
    
    def _execute_scan(
        self,
        scan_id: int,
        command: list,
        output_file: str,
        scan_type: str
    ) -> None:
        """
        Ejecuta scan en thread separado.
        
        Args:
            scan_id: ID del escaneo
            command: Comando a ejecutar
            output_file: Archivo de salida
            scan_type: Tipo de scan para logging
        """
        from celery_app import get_flask_app
        
        app = get_flask_app()
        
        with app.app_context():
            try:
                # Obtener scan para workspace_id y escribir log inicial
                scan = self.scan_repo.find_by_id(scan_id)
                workspace_id = scan.workspace_id if scan else None
                
                command_str = ' '.join([c for c in command if c not in ['>', '2>&1']])
                logger.info(f"Executing {scan_type} scan {scan_id}: {command_str}")
                
                # Log inicial al workspace
                if workspace_id:
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source=scan_type.upper(),
                        level='INFO',
                        message=f"Iniciando {scan_type}: {command_str}",
                        metadata={'command': command_str, 'scan_id': scan_id}
                    )
                
                # Actualizar progreso al inicio de ejecución (25%)
                logger.info(f"Recon scan {scan_id}: Updating progress to 25%")
                self.scan_repo.update_progress(scan, 25, f"Ejecutando {scan_type}...")
                
                # Log al workspace sobre el inicio de ejecución
                if workspace_id:
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source=scan_type.upper(),
                        level='INFO',
                        message=f"Ejecutando comando: {command_str}",
                        metadata={'scan_id': scan_id, 'progress': 25}
                    )
                
                # Ejecutar comando
                logger.info(f"Recon scan {scan_id}: Starting command execution")
                result = subprocess.run(
                    command,
                    capture_output=True,
                    text=True,
                    timeout=1800,  # 30 minutos
                    env=CommandSanitizer.get_safe_env()
                )
                
                logger.info(f"Recon scan {scan_id}: Command finished with returncode {result.returncode}")
                
                # Actualizar progreso durante procesamiento (75%)
                scan = self.scan_repo.find_by_id(scan_id)
                logger.info(f"Recon scan {scan_id}: Updating progress to 75%")
                self.scan_repo.update_progress(scan, 75, "Procesando resultados...")
                
                # Log al workspace sobre el procesamiento
                if workspace_id:
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source=scan_type.upper(),
                        level='INFO',
                        message=f"Procesando resultados del comando...",
                        metadata={'scan_id': scan_id, 'progress': 75}
                    )
                
                # Guardar output si no se guardó automáticamente
                if not Path(output_file).exists() and result.stdout:
                    with open(output_file, 'w') as f:
                        f.write(result.stdout)
                
                # Actualizar scan (ya lo tenemos de antes, pero refrescamos por si cambió)
                scan = self.scan_repo.find_by_id(scan_id)
                workspace_id = scan.workspace_id if scan else None
                
                if result.returncode == 0:
                    self.scan_repo.update_status(scan, 'completed')
                    self.scan_repo.update_progress(scan, 100, result.stdout[:1000])
                    logger.info(f"Recon scan {scan_id} completed successfully")
                    
                    # Log de éxito
                    if workspace_id:
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source=scan_type.upper(),
                            level='INFO',
                            message=f"{scan_type} completado exitosamente",
                            metadata={'scan_id': scan_id, 'output_file': output_file}
                        )
                else:
                    error_msg = result.stderr or "Unknown error"
                    self.scan_repo.update_status(scan, 'failed', error_msg)
                    logger.error(f"Recon scan {scan_id} failed: {error_msg}")
                    
                    # Log de error
                    if workspace_id:
                        log_to_workspace(
                            workspace_id=workspace_id,
                            source=scan_type.upper(),
                            level='ERROR',
                            message=f"{scan_type} falló: {error_msg}",
                            metadata={'scan_id': scan_id, 'error': error_msg}
                        )
                    
            except subprocess.TimeoutExpired:
                scan = self.scan_repo.find_by_id(scan_id)
                workspace_id = scan.workspace_id if scan else None
                self.scan_repo.update_status(scan, 'failed', 'Timeout exceeded (30 min)')
                logger.error(f"Recon scan {scan_id} timeout")
                
                if workspace_id:
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source=scan_type.upper(),
                        level='ERROR',
                        message=f"{scan_type} timeout (30 minutos)",
                        metadata={'scan_id': scan_id}
                    )
                
            except Exception as e:
                scan = self.scan_repo.find_by_id(scan_id)
                workspace_id = scan.workspace_id if scan else None
                self.scan_repo.update_status(scan, 'failed', str(e))
                logger.error(f"Recon scan {scan_id} error: {e}", exc_info=True)
                
                if workspace_id:
                    log_to_workspace(
                        workspace_id=workspace_id,
                        source=scan_type.upper(),
                        level='ERROR',
                        message=f"Error en {scan_type}: {str(e)}",
                        metadata={'scan_id': scan_id, 'error': str(e)}
                    )
